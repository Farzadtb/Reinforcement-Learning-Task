{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e7e21e",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17192d95",
   "metadata": {},
   "source": [
    "Here we'll also define a few parameters, one of which, gamma, will determine how much future prizes are discounted\n",
    "by the passage of time, thereby influencing \"how many moves before winning or losing\" we award in the future. \n",
    "Soon, we'll have a more in-depth chat about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c538ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "# gym initialization\n",
    "env = gym.make('Pong-v0')\n",
    "observation = env.reset()\n",
    "prev_input = None\n",
    "# Declaring the two actions that can happen in Pong for an agent, move up or move down\n",
    "# Decalring 0 means staying still. Note that this is pre-defined specific to package.\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "# Hyperparameters. Gamma here allows you to measure the effect of future events\n",
    "gamma = 0.99\n",
    "# initialization of variables used in the main loop\n",
    "x_train, y_train, rewards = [],[],[]\n",
    "reward_sum = 0\n",
    "episode_nb = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6f86ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using the pyplot tool, let's have a look at the Pong a frame, the most fundamental data unit in the context of the game.\n",
    "#In this mode, our own policy model will replace OpenAI's Pong AIs, which power the game's agents.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "env = gym.make('Pong-v0') # environment info\n",
    "observation = env.reset()\n",
    "# The ball is released after 20 frames\n",
    "for i in range(22):\n",
    " \n",
    " if i > 20:\n",
    "     plt.imshow(observation)\n",
    "     plt.show()\n",
    "     observation, _, _, _ = env.step(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6504bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We could keep plotting more frames to watch the game's flow by adjusting the range of the loop, but for now we'll forego that.\n",
    "#It's important to keep in mind that the OpenAI gym environment handles tracking incentives internally, \n",
    "#so this frame doesn't need to provide that information. To prepare our frame for a one-dimensional neural network,\n",
    "# we'll crop it and grayscale it before flattening the output.\n",
    "\n",
    "def pre_process(I):\n",
    "# prepro 210x160x3 frame into 6400 (80x80) 1D float vector\n",
    " I = I[35:195] # crop\n",
    " I = I[::2,::2,0] # downsample by factor of 2\n",
    " I[I == 144] = 0 # erase background (background type 1)\n",
    " I[I == 109] = 0 # erase background (background type 2)\n",
    " I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    " return I.astype(float).ravel()\n",
    "#Show\n",
    "preprocessedobs_preprocessed = pre_process(observation).reshape(80,80)\n",
    "plt.imshow(preprocessedobs_preprocessed, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc87f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can include a discount function that uses a decay rate (gamma, defined above) \n",
    "#to split the normalized earned reward among the preceding frames:\n",
    "\n",
    "def dis_rewards(r, gamma):\n",
    "#take 1D float array of rewards and compute discounted reward\n",
    "    r = np.array(r)\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    \n",
    "    for t in reversed(range(0, r.size)):\n",
    "        if r[t] != 0: running_add = 0 # if the game ended (in Pong), reset \n",
    "        running_add = running_add * gamma + r[t] \n",
    "        discounted_r[t] = running_add\n",
    "    discounted_r -= np.mean(discounted_r) #normalizing the result\n",
    "    discounted_r /= np.std(discounted_r) #idem using standar deviation\n",
    "    return discounted_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f8ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               1280200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,401\n",
      "Trainable params: 1,280,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Now that we know what we're working with, we can define our model as a two-layer, densely-connected structure. \n",
    "#Our images are pixel-based, thus they can be represented by 1D arrays, making them suitable for a fully-connected neural network.\n",
    "# However, convolutional models are also conceivable (and have considerably fewer parameters).\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.optimizers import Adam \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200,input_dim=80*80, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='RandomNormal'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the model, we can start putting it through its paces in network training. \n",
    "#To kick off the data gathering procedure, let's first use the aforementioned preprocessing method to ready our inputs. \n",
    "#Then, the current network is fed our input and an action, signifying an upward or downward translation, is predicted. \n",
    "#Our datasets are then ready for training after we have appended our x and y variables. \n",
    "#The Pong environment also takes in information about our activities and uses it to calculate and save a reward score.\n",
    "\n",
    "history = []\n",
    "observation = env.reset()\n",
    "prev_input = None\n",
    "while (True):\n",
    " cur_input = pre_process(observation)\n",
    " \n",
    " x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
    " prev_input = cur_input \n",
    " proba = model.predict(np.expand_dims(x, axis=1).T)\n",
    " action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
    " y = 1 if action == 2 else 0 \n",
    "x_train.append(x)\n",
    "y_train.append(y)\n",
    "observation, reward, done, info = env.step(action)\n",
    "rewards.append(reward)\n",
    "reward_sum += reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3301e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If done\n",
    "\n",
    "history.append(reward_sum)\n",
    "print(‘At the end of episode’, episode_nb, ‘the total reward was :’, reward_sum)\n",
    "if episode_nb>=3000 and reward_sum >=-12:\n",
    "break\n",
    "else:\n",
    "episode_nb += 1\n",
    "\n",
    "# training\n",
    "model.fit(x=np.vstack(x_train), y=np.vstack(y_train), verbose=1, sample_weight=dis_rewards(rewards, gamma))\n",
    "\n",
    "\n",
    "# Reinitialization\n",
    "x_train, y_train, rewards = [],[],[]\n",
    "observation = env.reset()\n",
    "reward_sum = 0\n",
    "prev_input = None\n",
    "plt.plot(history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a90c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
